# Ceph

## 特点

可伸缩性

>Ceph 能够快速扩展，而无需其他解决方案所需的典型停机时间。 使用先进的 `CRUSH` 算法，Ceph 克服了所有可扩展性挑战，引领了实现真正灵活、极具弹性的大规模存储的道路。 停止依赖昂贵的、特定于供应商的硬件和锁定合同。 打破传统限制。 随着您的业务扩展，您的存储集群呈指数增长。 Ceph 是一种可扩展、经济高效的解决方案，可用于企业市场、学术机构等领域快速且不可预测的数据增长。

可靠性

>数据是不可替代的，因此存储系统的可靠性和微调管理至关重要。 使用 Ceph 实现安心； 自我管理和自我修复，Ceph 在您意识到问题之前发现并纠正问题。 在您的存储集群中，`Ceph Monitor` 和 `Ceph Manager` 守护进程协调以提高互连系统之间的可靠性和数据可用性。 CRUSH 算法降低了单点故障、性能瓶颈和可扩展性限制的风险，创建了一个可靠且高性能的存储解决方案，适合不断增长的企业市场。

高性能

>Ceph 的配置和部署可以完全根据您的需求量身定制，而不会影响性能。 将 Ceph 应用到您现有的存储设置，或使用广泛可用的商品硬件创建新集群，以实现行业领先的可靠性和可扩展性，而无需花费传统的专有 ICT 基础设施。在传统存储系统面临延迟、复杂的数据复制过程和需要特定的、不灵活的物理基础设施的情况下，Ceph 仍然保持高性能和可扩展性。作为一个软件定义的存储系统，Ceph 旨在最大限度地提高效率和性能，而不管它运行在什么基础架构上。

多存储类型支持

>Ceph 支持对象存储，文件存储以及块存储

硬件无关

>Ceph 可以部署在常用且广泛可用的硬件上，以最少的硬件投资为您提供无限的存储可扩展性，从而降低成本并且没有供应商锁定。 购买您需要的硬件，或使用您已有的硬件，部署 Ceph，然后让软件完成剩下的工作。 通过这种灵活的方法来构建经济高效的基础设施系统，从而降低您的 OPEX。

## 组成

Monitors：

>Ceph Monitor ( ceph-mon) 维护集群状态的映射，包括监视器映射、管理器映射、OSD 映射、MDS 映射和 CRUSH 映射。这些映射是 Ceph 守护进程相互协调所需的关键集群状态。监视器还负责管理守护进程和客户端之间的身份验证。通常至少需要三个监视器才能实现冗余和高可用性。

Ceph Mgr：

>Ceph 管理器守护进程 ( ceph-mgr) 负责跟踪运行时指标和 Ceph 集群的当前状态，包括存储利用率、当前性能指标和系统负载。Ceph 管理器守护进程还托管基于 Python 的模块来管理和公开 Ceph 集群信息，包括基于 Web 的Ceph 仪表板和 REST API。高可用性通常至少需要两个管理器。

Ceph OSD：

>Ceph OSD（对象存储守护进程 ceph-osd）存储数据，处理数据复制、恢复、重新平衡，并通过检查其他 Ceph OSD 守护进程的心跳来向 Ceph 监视器和管理器提供一些监控信息。通常至少需要 3 个 Ceph OSD 来实现冗余和高可用性。

MDS：

>Ceph 元数据服务器（MDS，ceph-mds）代表Ceph 文件系统存储元数据（即 Ceph 块设备和 Ceph 对象存储不使用 MDS）。Ceph的元数据服务器允许POSIX文件系统的用户来执行基本的命令（如 ls，find没有放置在一个Ceph存储集群的巨大负担，等等）。

## CRUSH算法

Ceph 将数据作为对象存储在逻辑存储池中，使用CRUSH算法，Ceph计算出对象应该放在哪个PG(placement group)里，以及这个PG应该包含在哪个OSD Daemon里。CRUSH 算法使 Ceph 存储集群能够动态扩展、重新平衡和恢复。

## BlueStore

BlueStore 是一种特殊用途的存储后端，专为管理 Ceph OSD 工作负载的磁盘数据而设计。BlueStore 的设计基于十年支持和管理 Filestore OSD 的经验。

BlueStore 的主要功能包括：

- 直接管理存储设备。BlueStore 使用原始块设备或分区。这避免了可能限制性能或增加复杂性的中间抽象层（例如 XFS 等本地文件系统）。

- 使用 RocksDB 进行元数据管理。嵌入 RocksDB 的键/值数据库是为了管理内部元数据，包括对象名称到磁盘块位置的映射。

- 完整数据和元数据校验和。默认情况下，写入 BlueStore 的所有数据和元数据都受到一个或多个校验和的保护。未经验证，不会从磁盘读取数据或元数据返回给用户

- 内联压缩。数据在写入磁盘之前可以选择压缩。

- 多设备元数据分层。BlueStore 允许将其内部日志（预写日志）写入单独的高速设备（如 SSD、NVMe 或 NVDIMM）以提高性能。如果有大量更快的存储可用，内部元数据可以存储在更快的设备上。

- 高效的写时复制。RBD 和 CephFS 快照依赖于在 BlueStore 中有效实施的写时复制克隆机制。这为常规快照和纠删码池（依靠克隆实现高效的两阶段提交）带来了高效的 I/O。

## 纠删码
